{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork():\n",
    "    \"\"\"\n",
    "    My implementation of a Neural Network Classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    acti_fns = ['relu', 'sigmoid', 'linear', 'tanh', 'softmax']\n",
    "    weight_inits = ['zero', 'random', 'normal']\n",
    "\n",
    "    def __init__(self, n_layers, layer_sizes, activation, learning_rate, weight_init, batch_size, num_epochs):\n",
    "        \"\"\"\n",
    "        Initializing a new MyNeuralNetwork object\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_layers : int value specifying the number of layers\n",
    "\n",
    "        layer_sizes : integer array of size n_layers specifying the number of nodes in each layer\n",
    "\n",
    "        activation : string specifying the activation function to be used\n",
    "                     possible inputs: relu, sigmoid, linear, tanh\n",
    "\n",
    "        learning_rate : float value specifying the learning rate to be used\n",
    "\n",
    "        weight_init : string specifying the weight initialization function to be used\n",
    "                      possible inputs: zero, random, normal\n",
    "\n",
    "        batch_size : int value specifying the batch size to be used\n",
    "\n",
    "        num_epochs : int value specifying the number of epochs to be used\n",
    "        \"\"\"\n",
    "\n",
    "        if activation not in self.acti_fns:\n",
    "            raise Exception('Incorrect Activation Function')\n",
    "\n",
    "        if weight_init not in self.weight_inits:\n",
    "            raise Exception('Incorrect Weight Initialization Function')\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_init = weight_init\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def relu(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the ReLU activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return X * (X>=0)\n",
    "\n",
    "    def relu_grad(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the gradient of ReLU activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return 1*(X>=0)\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the Sigmoid activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return 1/(1+np.exp(-X))\n",
    "\n",
    "    def sigmoid_grad(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the gradient of Sigmoid activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return self.sigmoid(X) *(1-self.sigmoid (X))\n",
    "\n",
    "    def linear(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the Linear activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return X\n",
    "\n",
    "    def linear_grad(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the gradient of Linear activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return np.ones(X.shape)\n",
    "\n",
    "    def tanh(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the Tanh activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return np.tanh(X)\n",
    "\n",
    "    def tanh_grad(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the gradient of Tanh activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return 1-self.tanh(X)*self.tanh(X)\n",
    "\n",
    "    def softmax(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the ReLU activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        exp = np.exp(X)\n",
    "        return exp/(np.sum(exp,axis = 1, keepdims = True))\n",
    "\n",
    "    def softmax_grad(self, X):\n",
    "        \"\"\"\n",
    "        Calculating the gradient of Softmax activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 1-dimentional numpy array \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_calc : 1-dimensional numpy array after calculating the necessary function over X\n",
    "        \"\"\"\n",
    "        return None\n",
    "    \n",
    "    def zero_init(self, shape):\n",
    "        \"\"\"\n",
    "        Calculating the initial weights after Zero Activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : tuple specifying the shape of the layer for which weights have to be generated \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        weight : 1-dimensional numpy array which contains the initial weights for the requested layer\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        weight = np.zeros(shape)\n",
    "        return weight\n",
    "\n",
    "    def random_init(self, shape):\n",
    "        \"\"\"\n",
    "        Calculating the initial weights after Random Activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : tuple specifying the shape of the layer for which weights have to be generated \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        weight : 1-dimensional numpy array which contains the initial weights for the requested layer\n",
    "        \"\"\"\n",
    "        weight = np.random.rand(shape[0], shape[1])\n",
    "        return weight\n",
    "\n",
    "    def normal_init(self, shape):\n",
    "        \"\"\"\n",
    "        Calculating the initial weights after Normal(0,1) Activation for a particular layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape : tuple specifying the shape of the layer for which weights have to be generated \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        weight : 1-dimensional numpy array which contains the initial weights for the requested layer\n",
    "        \"\"\"\n",
    "        weight = np.random.normal(size = shape)*0.01\n",
    "        return weight\n",
    "\n",
    "    def fit(self, X, y, x_test = None, y_test = None):\n",
    "        \"\"\"\n",
    "        Fitting (training) the linear model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as training data.\n",
    "\n",
    "        y : 1-dimensional numpy array of shape (n_samples,) which acts as training labels.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : an instance of self\n",
    "        \"\"\"\n",
    "\n",
    "        # fit function has to return an instance of itself or else it won't work with test.py\n",
    "        \n",
    "        \n",
    "        y = self.expand_labels(y)\n",
    "        \n",
    "        m , n_0 = X.shape\n",
    "        n_l = y.shape[1]\n",
    "\n",
    "        parameters = self.initialization()\n",
    "        self.parameters = parameters\n",
    "\n",
    "        train_loss_history = []\n",
    "        train_accuracy_history = []\n",
    "        test_loss_history = []\n",
    "        test_accuracy_history = []\n",
    "\n",
    "        \n",
    "\n",
    "        for epoch in tqdm(range(self.num_epochs), desc = \"Progress Total : \", position = 0, leave = True):\n",
    "\n",
    "\n",
    "            n_batches = m//self.batch_size\n",
    "            X_batches = [X[self.batch_size*i:self.batch_size*(i+1),:] for i in range(0,n_batches)]\n",
    "            y_batches = [y[self.batch_size*i:self.batch_size*(i+1),:] for i in range(0,n_batches)]\n",
    "\n",
    "            train_batch_loss = []\n",
    "            test_batch_loss = []\n",
    "            train_batch_accuracy = []\n",
    "            test_batch_accuracy = []\n",
    "\n",
    "            for curr_x, curr_y in tqdm(zip(X_batches,y_batches), desc = \"Progress Epoch: \" + str(epoch+1) + \"/\" + str(self.num_epochs), position = 0, leave = True, total = len(X_batches)):\n",
    "                A, activations, preactivations = self.forward_prop(curr_x,parameters)\n",
    "\n",
    "                train_cost = self.cross_entropy_loss(A,curr_y)\n",
    "                train_batch_loss.append(train_cost)\n",
    "#                 print(A)\n",
    "                self.backward_prop(curr_x,curr_y,preactivations, activations )\n",
    "#                 train_batch_accuracy.append(self.score(curr_x,np.argmax(curr_y,axis = 1)))\n",
    "                if(x_test is not None):\n",
    "                    proba = self.predict_proba(x_test)\n",
    "#                     print(proba.shape)\n",
    "                    test_loss = self.cross_entropy_loss(proba, self.expand_labels(y_test))\n",
    "                    test_batch_loss.append(test_loss)\n",
    "#                     test_batch_accuracy.append(self.score(x_test, y_test))\n",
    "                    \n",
    "#             print(\"Training Accuracy : \", np.array(train_batch_accuracy).mean())\n",
    "#             print(\"Validation Accuracy : \", np.array(test_batch_accuracy).mean())\n",
    "            print(\"Validation loss : \" ,np.array(test_batch_loss).mean())\n",
    "            print(\"Training Loss : \", np.array(train_batch_loss).mean())\n",
    "            \n",
    "\n",
    "\n",
    "            train_loss_history.append( np.array(train_batch_loss).mean())\n",
    "#             train_accuracy_history.append( np.array(train_batch_accuracy).mean())\n",
    "            test_loss_history.append( np.array(test_batch_loss).mean())\n",
    "#             test_accuracy_history.append(  np.array(test_batch_accuracy).mean())\n",
    "                \n",
    "                \n",
    "        \n",
    "        self.train_loss_history = train_loss_history\n",
    "        self.train_accuracy_history = train_accuracy_history\n",
    "        self.test_loss_history = test_loss_history\n",
    "        self.test_accuracy_history = test_accuracy_history\n",
    "        \n",
    "        \n",
    "        self.parameters = parameters\n",
    "\n",
    "\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def initialization(self):\n",
    "        parameters = {}\n",
    "        layers = self.layer_sizes\n",
    "        \n",
    "        for i in range(0,len(layers)-1):\n",
    "            if(self.weight_init == 'zero'):\n",
    "                curr_layer = self.zero_init((layers[i],layers[i+1]))\n",
    "\n",
    "            elif(self.weight_init == 'random'):\n",
    "                curr_layer = self.random_init((layers[i],layers[i+1]))\n",
    "\n",
    "            else:\n",
    "                curr_layer = self.normal_init((layers[i],layers[i+1]))\n",
    "\n",
    "            parameters[\"W\" + str(i+1)] = curr_layer\n",
    "            parameters[\"b\" + str(i+1)] = np.zeros((1,layers[i+1]))\n",
    "\n",
    "        self.parameters = parameters\n",
    "\n",
    "        return parameters\n",
    "        \n",
    "    \n",
    "    def forward_prop(self,X,parameters):\n",
    "\n",
    "        \"\"\"\n",
    "        Implements one forward propagation of the deep neural network.\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        X : Training set to be forward propagated\n",
    "        parameters : model parameters \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A_l : Activations of the final layer\n",
    "        forward_cache : list contraining all the linear_cache and activation_cache of all the layers\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        A = X\n",
    "        L = len(parameters)//2\n",
    "\n",
    "        activations = {}\n",
    "        preactivations = {}\n",
    "\n",
    "        for i in range(0,L-1):\n",
    "            A_prev = A\n",
    "#             print(A_prev.shape)\n",
    "            \n",
    "            Z = np.dot(A_prev, parameters[\"W\" + str(i+1)]) + parameters[\"b\" + str(i+1)]\n",
    "\n",
    "            if(self.activation == \"relu\"):\n",
    "                A = self.relu(Z)\n",
    "\n",
    "            elif (self.activation == \"tanh\"):\n",
    "                A = self.tanh(Z)\n",
    "\n",
    "            elif (self.activation == \"linear\"):\n",
    "                A = self.linear(Z)\n",
    "\n",
    "            elif (self.activation == \"sigmoid\"):\n",
    "                A = self.sigmoid(Z)\n",
    "\n",
    "            preactivations[\"Z\" + str(i+1)] = Z\n",
    "            activations[\"A\" + str(i+1)] = A           \n",
    "            A_prev = A\n",
    "        \n",
    "        \n",
    "        Z_l = np.dot(A_prev, parameters[\"W\" + str(L)]) + parameters[\"b\" + str(L)]        \n",
    "        A_l = self.softmax(Z_l)\n",
    "        preactivations[\"Z\" + str(L)] = Z_l\n",
    "        activations[\"A\" + str(L)] = A_l\n",
    "\n",
    "        return A_l, activations, preactivations\n",
    "    \n",
    "        \n",
    "    def backward_prop(self, X, Y, preactivations, activations):\n",
    "        \n",
    "        \"\"\"\n",
    "        Implements backward propagation of the complete model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : The ground truth labels of the curr training set\n",
    "        A_l : activations of the final layer of the model\n",
    "        cache : tuple containing the linear_cache and activation_cache\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gradients : Dictionary containing the gradient vectors for each layer of the model\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        derivatives = {}\n",
    "        L = len(activations)\n",
    "        activations[\"A0\"] = X\n",
    "\n",
    "        A = activations[\"A\" + str(L)]\n",
    "        dZ = A - Y\n",
    "\n",
    "        dW = np.dot(activations[\"A\" + str(L-1) ].T, dZ)/len(X)\n",
    "        db = np.sum(dZ, axis=0, keepdims=True) / len(X)\n",
    "\n",
    "        dAPrev = np.dot(dZ, self.parameters[\"W\" + str(L)].T)\n",
    "\n",
    "        derivatives[\"dW\" + str(L)] = dW\n",
    "        derivatives[\"db\" + str(L)] = db\n",
    "\n",
    "        for l in range(L - 1, 0, -1):\n",
    "            if(self.activation == \"relu\"):\n",
    "                dact = self.relu_grad(preactivations[\"Z\" + str(l)])\n",
    "\n",
    "            elif (self.activation == \"tanh\"):\n",
    "                dact = self.tanh_grad(preactivations[\"Z\" + str(l)])\n",
    "\n",
    "            elif (self.activation == \"linear\"):\n",
    "                dact = self.linear_grad(preactivations[\"Z\" + str(l)])\n",
    "\n",
    "            elif (self.activation == \"sigmoid\"):\n",
    "                dact = self.sigmoid_grad(preactivations[\"Z\" + str(l)])\n",
    "\n",
    "            dZ = dAPrev * dact\n",
    "            dW = (1/len(X)) * np.dot(activations[\"A\" + str(l - 1)].T, dZ)\n",
    "            db = (1/len(X)) * np.sum(dZ, axis=0, keepdims=True)\n",
    "            if l > 1:\n",
    "                dAPrev = np.dot(dZ,self.parameters[\"W\" + str(l)].T)\n",
    "\n",
    "            derivatives[\"dW\" + str(l)] = dW\n",
    "            derivatives[\"db\" + str(l)] = db\n",
    "\n",
    "\n",
    "        for i in range(0,L):\n",
    "            self.parameters[\"W\" + str(i+1)] = self.parameters[\"W\" + str(i+1)] - self.learning_rate*derivatives[\"dW\" + str(i+1)]\n",
    "            self.parameters[\"b\" + str(i+1)] = self.parameters[\"b\" + str(i+1)] - self.learning_rate*derivatives[\"db\" + str(i+1)]\n",
    "        return \n",
    "    \n",
    "    \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predicting probabilities using the trained linear model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : 2-dimensional numpy array of shape (n_samples, n_classes) which contains the \n",
    "            class wise prediction probabilities.\n",
    "        \"\"\"\n",
    "\n",
    "        # return the numpy array y which contains the predicted values\n",
    "        proba,_,k = self.forward_prop(X,self.parameters)\n",
    "        return proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicting values using the trained linear model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.\n",
    "        \"\"\"\n",
    "\n",
    "        # return the numpy array y which contains the predicted values\n",
    "        proba = self.predict_proba(X)\n",
    "#         print(proba.shape)\n",
    "        y_pred = np.argmax(proba, axis = 1)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Predicting values using the trained linear model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.\n",
    "\n",
    "        y : 1-dimensional numpy array of shape (n_samples,) which acts as testing labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        acc : float value specifying the accuracy of the model on the provided testing set\n",
    "        \"\"\"\n",
    "\n",
    "        # return the numpy array y which contains the predicted values\n",
    "        y_pred = self.predict(X)\n",
    "        acc = (y_pred == y)\n",
    "        return acc.sum()/len(y)\n",
    "    \n",
    "    \n",
    "    def cross_entropy_loss(self, A, y):\n",
    "        n = len(y)\n",
    "        logp = - np.log(A[np.arange(n), y.argmax(axis=1)])\n",
    "        loss = np.sum(logp)/n\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def expand_labels(self, y):\n",
    "        m = len(y)\n",
    "        c = np.max(y)\n",
    "        new_y = np.zeros((m,c+1))\n",
    "        for i in range(m):\n",
    "            l = y[i]\n",
    "            new_y[i,l] = 1\n",
    "\n",
    "        return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/mnist/mnist_train.csv')\n",
    "test_df = pd.read_csv('dataset/mnist/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_df.to_numpy()\n",
    "testset = test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = dataset[:, 1:]/255\n",
    "X_test = testset[:, 1:]/255\n",
    "standardscalar = StandardScaler()\n",
    "X_train = standardscalar.fit_transform(X_train)\n",
    "X_test = standardscalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dataset[:, 0]\n",
    "y_test = testset[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid , 0.1, normal , 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MyNeuralNetwork(5, [784, 256, 128, 64, 10], 'sigmoid', 0.1, 'random', len(X_train)//20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 1/100: 100%|███████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss :  2.4573240993048175\n",
      "Training Loss :  2.5715989242456807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 2/100: 100%|███████████████████████████████████████████████████████████| 20/20 [00:06<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss :  2.3014263806807134\n",
      "Training Loss :  2.3015158299885274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 3/100: 100%|███████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss :  2.3014263805921713\n",
      "Training Loss :  2.3015158305675616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 4/100: 100%|███████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss :  2.3014263805921713\n",
      "Training Loss :  2.3015158305675625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 5/100: 100%|███████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss :  2.3014263805921713\n",
      "Training Loss :  2.3015158305675625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 6/100: 100%|███████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss :  2.301426380592172\n",
      "Training Loss :  2.3015158305675616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 7/100: 100%|███████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss :  2.3014263805921713\n",
      "Training Loss :  2.301515830567562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 8/100:  40%|████████████████████████                                    | 8/20 [00:03<00:04,  2.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-60b2b561b41f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-7f3ce7c330cd>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, x_test, y_test)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;31m#                 train_batch_accuracy.append(self.score(curr_x,np.argmax(curr_y,axis = 1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;31m#                     print(proba.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                     \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7f3ce7c330cd>\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;31m# return the numpy array y which contains the predicted values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m         \u001b[0mproba\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7f3ce7c330cd>\u001b[0m in \u001b[0;36mforward_prop\u001b[1;34m(self, X, parameters)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;31m#             print(A_prev.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m             \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# f = open(\"models/sigmoid\", \"wb\")\n",
    "# pickle.dump(nn,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9036"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([x for x in range(1,len(nn.train_loss_history) + 1, 1)],nn.train_loss_history, label = \"Average Training  Loss \" )\n",
    "plt.plot([x for x in range(1,len(nn.test_loss_history) + 1, 1)],nn.test_loss_history, label = \"Average Validation  Loss \" )\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tanh, 0.1, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MyNeuralNetwork(5, [784, 256, 128, 64, 10], 'relu', 0.1, 'random', len(X_train)//20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 1/100:   0%|                                                                    | 0/20 [00:00<?, ?it/s]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:523: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in greater_equal\n",
      "Progress Epoch: 1/100:   5%|███                                                         | 1/20 [00:00<00:09,  2.01it/s]C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in greater_equal\n",
      "Progress Epoch: 1/100: 100%|███████████████████████████████████████████████████████████| 20/20 [00:10<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss :  nan\n",
      "Training Loss :  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Epoch: 2/100:  60%|███████████████████████████████████▍                       | 12/20 [00:06<00:04,  1.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-60b2b561b41f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-7f3ce7c330cd>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, x_test, y_test)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;31m#                 train_batch_accuracy.append(self.score(curr_x,np.argmax(curr_y,axis = 1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;31m#                     print(proba.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                     \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7f3ce7c330cd>\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;31m# return the numpy array y which contains the predicted values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m         \u001b[0mproba\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7f3ce7c330cd>\u001b[0m in \u001b[0;36mforward_prop\u001b[1;34m(self, X, parameters)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;31m#             print(A_prev.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m             \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"models/tanh\", \"wb\")\n",
    "pickle.dump(nn,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([x for x in range(1,len(nn.train_loss_history) + 1, 1)],nn.train_loss_history, label = \"Average Training  Loss \" )\n",
    "plt.plot([x for x in range(1,len(nn.test_loss_history) + 1, 1)],nn.test_loss_history, label = \"Average Validation  Loss \" )\n",
    "plt.xlabel('Epochs ')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_nn = pickle.load(open(\"models/relu\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.00123514, 0.00197044, 0.00025005, ..., 0.00824354, 0.00869153,\n",
       "         0.00352182],\n",
       "        [0.00909308, 0.00865799, 0.00224581, ..., 0.00573072, 0.00455763,\n",
       "         0.00978907],\n",
       "        [0.00644419, 0.00596275, 0.00639801, ..., 0.00368183, 0.00765543,\n",
       "         0.00261152],\n",
       "        ...,\n",
       "        [0.00049213, 0.00306821, 0.00374583, ..., 0.00633159, 0.00406591,\n",
       "         0.00922146],\n",
       "        [0.00821146, 0.00413888, 0.00129525, ..., 0.00779239, 0.00082317,\n",
       "         0.00500184],\n",
       "        [0.00432546, 0.00446678, 0.0088842 , ..., 0.0070756 , 0.00905826,\n",
       "         0.00360253]]),\n",
       " 'b1': array([[-0.01136573, -0.06012103, -0.06625817, -0.09982769, -0.05657645,\n",
       "          0.01823025,  0.00377825, -0.11154891, -0.0542864 , -0.02488928,\n",
       "         -0.16572987, -0.01417219, -0.08996177, -0.03772061, -0.03606515,\n",
       "          0.00526073, -0.06370434, -0.0974894 ,  0.02524418, -0.08400137,\n",
       "         -0.00840822,  0.0088227 , -0.0157027 , -0.04337432,  0.00650432,\n",
       "         -0.04667714, -0.00725339, -0.01772745, -0.12320443,  0.02092815,\n",
       "         -0.02013203, -0.04924067, -0.10440968, -0.05738784, -0.03724919,\n",
       "         -0.01123115, -0.00416059,  0.00326349, -0.01934899, -0.04212154,\n",
       "         -0.0797631 , -0.00970613, -0.02003602, -0.02711246, -0.00408568,\n",
       "         -0.08357222,  0.10992259, -0.01377236, -0.03240947,  0.0195354 ,\n",
       "         -0.04718738, -0.00101512, -0.06060197, -0.0695347 ,  0.00488027,\n",
       "         -0.03171853,  0.03397355, -0.10221006, -0.07791213, -0.01462658,\n",
       "          0.03846062, -0.02094342, -0.09099854,  0.02225291, -0.02400665,\n",
       "          0.00249083, -0.02888632, -0.0168274 , -0.06085078,  0.03834081,\n",
       "          0.01008597, -0.0257538 , -0.02770276, -0.03214825, -0.02160287,\n",
       "         -0.01108826,  0.019943  , -0.03140033, -0.04806598, -0.0325561 ,\n",
       "         -0.06550288, -0.01670996, -0.03218921, -0.01055904, -0.01560462,\n",
       "         -0.057085  , -0.02748125, -0.05514931, -0.06056721, -0.02662592,\n",
       "         -0.01737126,  0.04703626, -0.0418499 ,  0.01278429, -0.00895003,\n",
       "          0.04726882, -0.01789772, -0.04635766, -0.1495109 , -0.05440784,\n",
       "         -0.00999229, -0.024598  ,  0.02237883, -0.09415913, -0.00612142,\n",
       "         -0.01597238, -0.00391056,  0.02829976, -0.00498424,  0.01581811,\n",
       "         -0.09397238, -0.0711147 , -0.09991086, -0.05056155, -0.01627284,\n",
       "         -0.01865031, -0.00025381, -0.00059048, -0.09265514, -0.03911581,\n",
       "         -0.03519038,  0.01208135, -0.0279962 ,  0.02860482, -0.03017769,\n",
       "         -0.01123272, -0.01748233, -0.0404588 ,  0.00844614,  0.01244786,\n",
       "         -0.07117034, -0.04319504, -0.12380428,  0.02517376, -0.05037141,\n",
       "         -0.02772328,  0.00806663, -0.02234874,  0.02841988,  0.00932158,\n",
       "         -0.04503701, -0.03507557, -0.09057659, -0.05559541, -0.01689556,\n",
       "         -0.00027781, -0.01552158, -0.02053161,  0.02038837, -0.04080984,\n",
       "         -0.02459712, -0.05095291,  0.01642742,  0.00364325,  0.00770091,\n",
       "         -0.03839865, -0.05143449,  0.0410813 , -0.0192798 ,  0.01570879,\n",
       "         -0.01071037, -0.0259946 ,  0.00176019, -0.03000422, -0.05522538,\n",
       "         -0.01913642, -0.04690597, -0.02523457, -0.06667393,  0.01750651,\n",
       "         -0.06380852, -0.05970478,  0.02873533,  0.00019205,  0.01346456,\n",
       "         -0.05970504, -0.1002282 ,  0.00711795, -0.06424303, -0.01905104,\n",
       "         -0.00062104, -0.06212206, -0.00123091, -0.00566295, -0.06205244,\n",
       "         -0.08644217, -0.02695714,  0.02342087, -0.02478677, -0.07036888,\n",
       "         -0.02082898, -0.05372496, -0.01577399,  0.00249616, -0.01681981,\n",
       "         -0.05298339, -0.01206999,  0.00631136,  0.01331137, -0.0311522 ,\n",
       "         -0.03342465, -0.10976909,  0.02699681, -0.06486799, -0.07670925,\n",
       "         -0.02318443, -0.03939937, -0.03320695,  0.03141877, -0.10871566,\n",
       "         -0.06282841, -0.01790856, -0.07180542, -0.09956045, -0.0245375 ,\n",
       "         -0.0388662 , -0.12651289, -0.13951394, -0.00483366, -0.0064112 ,\n",
       "         -0.03273647, -0.07531472, -0.01112184, -0.00502634, -0.01428994,\n",
       "         -0.0505664 ,  0.00638971,  0.01927006, -0.0025221 ,  0.03686205,\n",
       "         -0.01159814, -0.09322629, -0.05538222,  0.02893557, -0.06652407,\n",
       "         -0.00400675,  0.02627552, -0.00736   ,  0.01707392, -0.02700494,\n",
       "          0.05105117,  0.00121907, -0.05813094, -0.04818669, -0.03204987,\n",
       "          0.0130061 ,  0.02673616, -0.00409898,  0.03328406, -0.05482327,\n",
       "         -0.09330831, -0.00165843, -0.01039914, -0.05456253, -0.01009488,\n",
       "          0.00183531]]),\n",
       " 'W2': array([[ 0.02131787,  0.02589136,  0.02537291, ...,  0.02281923,\n",
       "          0.01975595,  0.02474544],\n",
       "        [ 0.02240665,  0.01974459,  0.03146482, ...,  0.03430853,\n",
       "          0.01933603,  0.02122436],\n",
       "        [ 0.01850003,  0.01185264,  0.0157653 , ...,  0.02097938,\n",
       "          0.02301245,  0.0137136 ],\n",
       "        ...,\n",
       "        [ 0.01834974,  0.03260859,  0.02837182, ...,  0.01276952,\n",
       "          0.03161915,  0.02524153],\n",
       "        [ 0.03775756,  0.01174109,  0.0421357 , ...,  0.0522694 ,\n",
       "         -0.00217631,  0.02453342],\n",
       "        [-0.00557944,  0.00497545, -0.01079166, ..., -0.00184347,\n",
       "          0.01548184, -0.00811817]]),\n",
       " 'b2': array([[-0.04776602, -0.05133506, -0.05149179, -0.0577991 , -0.04767937,\n",
       "         -0.04518786, -0.04573819, -0.04636909, -0.05099316, -0.05656328,\n",
       "         -0.05230271, -0.04493695, -0.05147764, -0.04975585, -0.05857148,\n",
       "         -0.04785753, -0.04293144, -0.05385158, -0.04827096, -0.04955729,\n",
       "         -0.0453469 , -0.0456399 , -0.05179963, -0.0468396 , -0.05439176,\n",
       "         -0.03414024, -0.05197276, -0.05114884, -0.0579089 , -0.04849307,\n",
       "         -0.0601764 , -0.04748391, -0.04335706, -0.0467677 , -0.04436303,\n",
       "         -0.04836839, -0.04574326, -0.05000103, -0.04025461, -0.04800479,\n",
       "         -0.05346298, -0.04413015, -0.05529566, -0.04939606, -0.04104169,\n",
       "         -0.05451752, -0.03433368, -0.05186603, -0.05044512, -0.04162822,\n",
       "         -0.05509255, -0.05207544, -0.05132988, -0.0548587 , -0.04720784,\n",
       "         -0.05423854, -0.05806535, -0.05229954, -0.03977659, -0.04258454,\n",
       "         -0.05514309, -0.04469805, -0.05466594, -0.04897903, -0.06002566,\n",
       "         -0.05257193, -0.04244791, -0.05119355, -0.04856103, -0.04840688,\n",
       "         -0.05214197, -0.05347642, -0.0543872 , -0.04529114, -0.04402789,\n",
       "         -0.0548642 , -0.05749612, -0.04400952, -0.0441127 , -0.05259654,\n",
       "         -0.04570282, -0.0518434 , -0.05984861, -0.0491957 , -0.05051564,\n",
       "         -0.05208246, -0.04685332, -0.04951641, -0.06037341, -0.00746651,\n",
       "         -0.05812741, -0.04440104, -0.03791882, -0.04934651, -0.0462863 ,\n",
       "         -0.04376465, -0.05415201, -0.05635092, -0.04492873, -0.04636508,\n",
       "         -0.04756671, -0.05343312, -0.04870716, -0.04900455, -0.05221458,\n",
       "         -0.05509318, -0.05178936, -0.04577008, -0.0618308 , -0.04552909,\n",
       "         -0.04413593, -0.05197974, -0.04437542, -0.05894828, -0.05421507,\n",
       "         -0.05407876, -0.00850118, -0.05319473, -0.04348365, -0.05233862,\n",
       "         -0.05103818, -0.04313569, -0.04848475, -0.04539718, -0.05019457,\n",
       "         -0.04289886, -0.06029752, -0.04872842]]),\n",
       " 'W3': array([[ 0.02808246,  0.01818411,  0.03646831, ...,  0.03207769,\n",
       "          0.03875615,  0.02927212],\n",
       "        [ 0.00431694,  0.05308171,  0.00266363, ...,  0.03114665,\n",
       "          0.03243601,  0.0175107 ],\n",
       "        [ 0.02366467,  0.02299875,  0.03013551, ...,  0.04040198,\n",
       "          0.04626381,  0.03161876],\n",
       "        ...,\n",
       "        [ 0.05848306, -0.0058553 ,  0.0635805 , ...,  0.02615254,\n",
       "          0.03001655,  0.01732557],\n",
       "        [ 0.00892956,  0.06884974,  0.0009038 , ...,  0.01121065,\n",
       "          0.01469115,  0.0166642 ],\n",
       "        [ 0.01582982,  0.03355152,  0.01082811, ...,  0.03973858,\n",
       "          0.03958332,  0.02554105]]),\n",
       " 'b3': array([[-0.10830107, -0.11521233, -0.11799667, -0.12648795, -0.06950602,\n",
       "         -0.0747483 , -0.13962636, -0.04730655, -0.1238203 , -0.0949694 ,\n",
       "         -0.13478196, -0.06740517, -0.08733315, -0.07043788, -0.11058142,\n",
       "         -0.0870291 , -0.07969753, -0.09432551, -0.14049835, -0.10293026,\n",
       "         -0.05185689, -0.04592586, -0.15106652, -0.09952247, -0.11267369,\n",
       "         -0.10811484, -0.0813549 , -0.07164631, -0.15064137, -0.04805081,\n",
       "         -0.12340072, -0.06832395, -0.13571703, -0.13620274, -0.10073081,\n",
       "         -0.1274645 , -0.07601988, -0.09151494, -0.10775155, -0.1163629 ,\n",
       "         -0.05454217, -0.10028315, -0.07143604, -0.08653872, -0.05192306,\n",
       "         -0.09389028, -0.10184324, -0.11744398, -0.13548846, -0.06898419,\n",
       "         -0.08931227, -0.06659981, -0.08550536, -0.03811774, -0.15686548,\n",
       "         -0.09637366, -0.0583115 , -0.14515149, -0.03158642, -0.08772832,\n",
       "         -0.04467095, -0.0799946 , -0.10204557, -0.14110556]]),\n",
       " 'W4': array([[ 0.08304795, -0.11181925,  0.19472521, -0.19628152,  0.19237036,\n",
       "         -0.09689593,  0.23325457, -0.26686286, -0.00268268,  0.01279355],\n",
       "        [ 0.09161666, -0.15893271,  0.01189338,  0.27189477, -0.24881292,\n",
       "          0.1857201 , -0.19761943,  0.01645591,  0.02973511,  0.06512584],\n",
       "        [ 0.09191555, -0.11878813,  0.20692961, -0.2198491 ,  0.23835651,\n",
       "         -0.13416591,  0.26470913, -0.28736016, -0.02141294,  0.02835136],\n",
       "        [ 0.17044253, -0.12899796,  0.05741508, -0.07542745, -0.13029275,\n",
       "          0.1358812 ,  0.15412804, -0.1610894 ,  0.19174842, -0.16244782],\n",
       "        [ 0.0121101 , -0.11287531,  0.29305911, -0.23424443,  0.51858099,\n",
       "         -0.36204458,  0.31007111, -0.37272868, -0.10922974,  0.11186209],\n",
       "        [ 0.12327463, -0.08832917,  0.01600884,  0.07083429, -0.14274314,\n",
       "          0.15797247,  0.02603548, -0.18007808,  0.16317988, -0.07919403],\n",
       "        [ 0.17110187, -0.11083916,  0.0307967 ,  0.10300994, -0.17196763,\n",
       "          0.19611009,  0.00208562, -0.21232974,  0.12801328, -0.07553734],\n",
       "        [ 0.1110971 , -0.09473722,  0.00164712,  0.01269589, -0.12924052,\n",
       "          0.13865483,  0.06204884, -0.14934623,  0.19972035, -0.10594202],\n",
       "        [ 0.15570739, -0.10247301,  0.05125705,  0.06081059, -0.16816639,\n",
       "          0.16592403,  0.03997401, -0.19706627,  0.13292143, -0.09544184],\n",
       "        [ 0.14228892, -0.12544993,  0.0239281 , -0.16884811, -0.06433802,\n",
       "          0.0962468 ,  0.21061683, -0.141483  ,  0.2138612 , -0.15241805],\n",
       "        [ 0.16158425, -0.11468601,  0.07413504, -0.11112475, -0.07969173,\n",
       "          0.09249983,  0.17348037, -0.13452728,  0.15215883, -0.14976905],\n",
       "        [ 0.03350251, -0.19105616,  0.01425941,  0.34712665, -0.33932043,\n",
       "          0.17369817, -0.35872552,  0.26583915, -0.05360073,  0.15772311],\n",
       "        [ 0.16768152, -0.10646349, -0.02801237, -0.02533084, -0.16041113,\n",
       "          0.18860799,  0.08220261, -0.15496839,  0.21057758, -0.126197  ],\n",
       "        [ 0.06199891, -0.19104588, -0.02167621,  0.3404524 , -0.33704513,\n",
       "          0.1937233 , -0.33823333,  0.235867  , -0.03026753,  0.14325219],\n",
       "        [ 0.16356188, -0.10395573,  0.02071353, -0.00418894, -0.14653649,\n",
       "          0.15785131,  0.07030221, -0.16166301,  0.14832068, -0.11336543],\n",
       "        [ 0.13336328, -0.13396533,  0.05848479, -0.19756133,  0.00277273,\n",
       "          0.05879512,  0.24843741, -0.17759338,  0.21186972, -0.15197851],\n",
       "        [ 0.12870328, -0.11033491,  0.0302993 , -0.16749246, -0.03360019,\n",
       "          0.07221853,  0.21222779, -0.14276381,  0.20481109, -0.13297821],\n",
       "        [ 0.17132006, -0.12057557,  0.00840929,  0.0062141 , -0.18585927,\n",
       "          0.19909404,  0.0740415 , -0.19540172,  0.23052366, -0.14000107],\n",
       "        [ 0.13580988, -0.11807772,  0.13757047, -0.18327283,  0.07184963,\n",
       "         -0.01184549,  0.24875858, -0.20596137,  0.06938057, -0.08275946],\n",
       "        [ 0.16007491, -0.11094365,  0.03575571, -0.06854554, -0.14108474,\n",
       "          0.13955382,  0.12705693, -0.15269998,  0.20126641, -0.13931051],\n",
       "        [ 0.12634662, -0.09689527, -0.00851843,  0.01651411, -0.14204565,\n",
       "          0.15633603,  0.06163798, -0.15758728,  0.21441661, -0.1144833 ],\n",
       "        [ 0.07593282, -0.11441122,  0.09998912, -0.21202644,  0.14558889,\n",
       "         -0.03507746,  0.25512295, -0.25954246,  0.12596653, -0.02846068],\n",
       "        [ 0.12952749, -0.12080361, -0.00239304,  0.21182333, -0.17842448,\n",
       "          0.19219534, -0.12658902, -0.11543901,  0.05199792,  0.01006159],\n",
       "        [ 0.08116492, -0.15124827,  0.00201071,  0.24497567, -0.2404196 ,\n",
       "          0.18919271, -0.16457465, -0.03264907,  0.07845332,  0.03409062],\n",
       "        [ 0.10319534, -0.16178852, -0.01494626,  0.26842605, -0.25248838,\n",
       "          0.21974642, -0.17133545, -0.07522771,  0.11042293,  0.03029234],\n",
       "        [ 0.14012001, -0.10415269,  0.02060449,  0.09340906, -0.15525682,\n",
       "          0.17537579,  0.00300167, -0.19181376,  0.1368489 , -0.07957114],\n",
       "        [ 0.03853071, -0.11052122,  0.2489984 , -0.24003993,  0.39198936,\n",
       "         -0.23831267,  0.27763404, -0.33906534, -0.07901996,  0.09932825],\n",
       "        [ 0.13544471, -0.09935403,  0.00701857, -0.03244584, -0.13651961,\n",
       "          0.147789  ,  0.08966626, -0.14082915,  0.20098819, -0.11877343],\n",
       "        [ 0.18730733, -0.11710465,  0.00527219,  0.11648868, -0.17189084,\n",
       "          0.22328264, -0.01064646, -0.21928897,  0.13666071, -0.09662936],\n",
       "        [ 0.10578231, -0.09294609,  0.00307812, -0.052492  , -0.10143496,\n",
       "          0.11330982,  0.11984805, -0.12683112,  0.20526842, -0.1198007 ],\n",
       "        [ 0.15681569, -0.14270899, -0.05882936,  0.19743992, -0.19628597,\n",
       "          0.25530368, -0.08718898, -0.2175022 ,  0.19917152, -0.0605865 ],\n",
       "        [ 0.03696968, -0.10851278,  0.23516294, -0.22760713,  0.36365754,\n",
       "         -0.22026247,  0.2606415 , -0.32887781, -0.04802876,  0.08186956],\n",
       "        [ 0.16756109, -0.10739538, -0.0280133 ,  0.13307033, -0.15050634,\n",
       "          0.21920602, -0.05066358, -0.19762714,  0.13364661, -0.07575144],\n",
       "        [ 0.1275793 , -0.11716038,  0.14017633, -0.18559035,  0.0736965 ,\n",
       "         -0.00692758,  0.23266241, -0.20851329,  0.06264772, -0.07901132],\n",
       "        [ 0.17916028, -0.11622138,  0.00308008,  0.03287572, -0.18274353,\n",
       "          0.20198524,  0.05197551, -0.20670266,  0.2062966 , -0.12579945],\n",
       "        [ 0.13077622, -0.12253049,  0.11707067, -0.15258708,  0.02455104,\n",
       "          0.02268256,  0.22009563, -0.17635191,  0.11348504, -0.1339051 ],\n",
       "        [ 0.10920553, -0.11969784,  0.06005975, -0.1677967 ,  0.02094685,\n",
       "          0.03897405,  0.21509319, -0.15439393,  0.16053754, -0.12166792],\n",
       "        [ 0.11416606, -0.12322372,  0.09178078, -0.18702304,  0.07330684,\n",
       "          0.01216899,  0.24472745, -0.19272873,  0.1299337 , -0.1040162 ],\n",
       "        [ 0.06817211, -0.09981314,  0.21106983, -0.18810681,  0.26799794,\n",
       "         -0.17745419,  0.23922932, -0.25318662, -0.06478648,  0.03935626],\n",
       "        [ 0.09929333, -0.17139187, -0.00993623,  0.29451228, -0.28381994,\n",
       "          0.20027962, -0.25399708,  0.0851308 , -0.00997814,  0.09437759],\n",
       "        [ 0.05525682, -0.1076603 ,  0.14018978, -0.22741583,  0.24106476,\n",
       "         -0.11251948,  0.26642502, -0.2821718 ,  0.04402411,  0.02809823],\n",
       "        [ 0.11158311, -0.12252605,  0.13973118, -0.19603009,  0.1147931 ,\n",
       "         -0.02209826,  0.24372532, -0.23451713,  0.09539584, -0.05990647],\n",
       "        [ 0.1228583 , -0.13672181,  0.05537155, -0.17006712, -0.01255755,\n",
       "          0.06757228,  0.23341515, -0.16671842,  0.23650218, -0.16700893],\n",
       "        [ 0.15194164, -0.09585281, -0.00128047,  0.05699317, -0.14677686,\n",
       "          0.17799093,  0.02235663, -0.18298422,  0.17300942, -0.09731127],\n",
       "        [ 0.12715952, -0.1070916 , -0.00650129, -0.0814279 , -0.11803149,\n",
       "          0.14026157,  0.13224083, -0.14782388,  0.25507561, -0.13743936],\n",
       "        [ 0.14136443, -0.09123556,  0.02511498, -0.07551014, -0.11805789,\n",
       "          0.11901386,  0.11445846, -0.12728646,  0.16803092, -0.1232739 ],\n",
       "        [ 0.17123985, -0.11015851,  0.00953026, -0.04961846, -0.15633582,\n",
       "          0.17499286,  0.10108569, -0.15715524,  0.20383039, -0.13659053],\n",
       "        [ 0.1084618 , -0.16403595, -0.02624657,  0.26829771, -0.2525057 ,\n",
       "          0.21315001, -0.2085965 , -0.00738982,  0.05188481,  0.05616274],\n",
       "        [ 0.13092975, -0.11738509,  0.05250898,  0.1579281 , -0.18194703,\n",
       "          0.17188449, -0.01967891, -0.23038329,  0.13284784, -0.05146917],\n",
       "        [ 0.09775891, -0.11566205,  0.08276216, -0.17414361,  0.04756752,\n",
       "          0.02094604,  0.21888296, -0.1723724 ,  0.16610362, -0.11887964],\n",
       "        [-0.05066172, -0.08374354,  0.36465167, -0.15619939,  0.70941606,\n",
       "         -0.58151812,  0.31760418, -0.40531188, -0.30896394,  0.23893694],\n",
       "        [ 0.1061042 , -0.1279463 ,  0.09278145, -0.20479031,  0.08972117,\n",
       "          0.00697137,  0.2547886 , -0.21077516,  0.17525737, -0.11243677],\n",
       "        [ 0.0734267 , -0.17470399, -0.00690709,  0.30119687, -0.29008773,\n",
       "          0.17929482, -0.30776143,  0.20167443, -0.0569253 ,  0.12869112],\n",
       "        [-0.02231534, -0.18414902,  0.00318983,  0.39964475, -0.39964577,\n",
       "          0.12671937, -0.53362158,  0.59763332, -0.21899466,  0.28249077],\n",
       "        [ 0.14063625, -0.14048219,  0.02168242,  0.2236558 , -0.20906773,\n",
       "          0.20934068, -0.10719381, -0.19289045,  0.11152199, -0.00881102],\n",
       "        [ 0.11951531, -0.12889058,  0.10679458, -0.16370857,  0.05208789,\n",
       "          0.01282199,  0.22895062, -0.1942177 ,  0.13779241, -0.116348  ],\n",
       "        [ 0.10982773, -0.11644371,  0.0278906 , -0.1466951 , -0.01932915,\n",
       "          0.06941906,  0.19954521, -0.14305913,  0.21194297, -0.13989051],\n",
       "        [ 0.14810563, -0.13936844, -0.05532863,  0.23734505, -0.19568359,\n",
       "          0.24416668, -0.12861654, -0.16593198,  0.13304535, -0.01696672],\n",
       "        [-0.07108738, -0.17328665,  0.00262733,  0.46652639, -0.4837059 ,\n",
       "          0.10040239, -0.6787327 ,  0.83708221, -0.31942511,  0.36621329],\n",
       "        [ 0.09619725, -0.14002091,  0.17827058, -0.25393967,  0.20444391,\n",
       "         -0.08076231,  0.29572821, -0.32748611,  0.08911762, -0.01244135],\n",
       "        [ 0.09327641, -0.11279541,  0.04247048, -0.14018096,  0.00408801,\n",
       "          0.05022149,  0.19911126, -0.15036848,  0.2059593 , -0.13053993],\n",
       "        [ 0.15422987, -0.09865283, -0.01748349, -0.09399863, -0.12771207,\n",
       "          0.14620622,  0.13307983, -0.133032  ,  0.22039139, -0.12300614],\n",
       "        [ 0.15481861, -0.11660904,  0.03506671, -0.10081811, -0.10912071,\n",
       "          0.12120311,  0.17063106, -0.14832101,  0.20689055, -0.14487379],\n",
       "        [ 0.15155075, -0.10142963,  0.07710699, -0.08540242, -0.08695326,\n",
       "          0.0886147 ,  0.14227556, -0.11638654,  0.10534868, -0.12802527]]),\n",
       " 'b4': array([[-4.21477674,  4.44193276, -1.88236548, -0.77296358,  1.46717634,\n",
       "         -1.11226053, -2.03653595,  2.08949302,  0.33646376,  1.6838364 ]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_nn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = relu_nn.parameters[\"W4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 63 nearest neighbors...\n",
      "[t-SNE] Indexed 64 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 64 samples in 0.142s...\n",
      "[t-SNE] Computed conditional probabilities for sample 64 / 64\n",
      "[t-SNE] Mean sigma: 0.252136\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 50.819557\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.168041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_em = TSNE(n_components=2, perplexity=30.0, n_iter=1000, verbose=1).fit_transform(W4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64,), (64,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_em[:,0].shape,tsne_em[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# plt.figure(figsize = (5,5))\n",
    "plt.scatter(tsne_em[:,0],tsne_em[:,1])\n",
    "# plt.scatter(tsne_em[:,0], tsne_em[:,1],color = \"green\", hue = y_train);\n",
    "# sns.scatterplot(x = df_tsne_pca_2d[\"x\"], y = df_tsne_pca_2d[\"y\"], hue = df_tsne_pca_2d[\"label\"], palette = sns.color_palette(\"husl\", 10) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=0.1, hidden_layer_sizes=(256,128,64), random_state=1, activation = 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.1, hidden_layer_sizes=(256, 128, 64), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.1,\n",
       "              hidden_layer_sizes=(256, 128, 64), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MLPClassifier(solver='lbfgs', alpha=0.1, hidden_layer_sizes=(256,128,64), random_state=1, activation = 'logistic')\n",
    "clf2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(256, 128, 64),\n",
       "              random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = MLPClassifier(solver='lbfgs', alpha=0.1, hidden_layer_sizes=(256,128,64), random_state=1, activation = 'tanh')\n",
    "clf3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.1,\n",
       "              hidden_layer_sizes=(256, 128, 64), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = MLPClassifier(solver='lbfgs', alpha=0.1, hidden_layer_sizes=(256,128,64), random_state=1, activation = 'identity')\n",
    "clf4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Relu Activation :  0.9767\n"
     ]
    }
   ],
   "source": [
    "s1 = clf.score(X_test,y_test)\n",
    "print(\"For Relu Activation : \", s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sigmoid/Logistic Activation :  0.9644\n"
     ]
    }
   ],
   "source": [
    "s2 = clf2.score(X_test,y_test)\n",
    "print(\"For Sigmoid/Logistic Activation : \", s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For tanh Activation :  0.9667\n"
     ]
    }
   ],
   "source": [
    "s3 = clf3.score(X_test,y_test)\n",
    "print(\"For tanh Activation : \", s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Linear/Identity Activation :  0.9767\n"
     ]
    }
   ],
   "source": [
    "s4 = clf.score(X_test,y_test)\n",
    "print(\"For Linear/Identity Activation : \", s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MYnn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_nn = pickle.load(open(\"models/relu\", \"rb\"))\n",
    "sigmoid_nn = pickle.load(open(\"models/sigmoid\", \"rb\"))\n",
    "linear_nn = pickle.load(open(\"models/linear2\", \"rb\"))\n",
    "tanh_nn =  pickle.load(open(\"models/tanh\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9388"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_nn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9036"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_nn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8163"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_nn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh_nn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

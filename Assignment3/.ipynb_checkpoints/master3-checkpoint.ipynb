{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/largeValidation_Q3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      2  0  0.1  1  1.1  1.2  0.2  0.3  0.4  0.5  ...  1.38  1.39  0.80  1.40  \\\n",
       "0    1  0    0  0    0    0    0    0    0    0  ...     0     0     0     0   \n",
       "1    2  0    0  1    1    1    1    0    0    0  ...     1     1     0     0   \n",
       "2    9  0    0  0    0    0    0    0    0    0  ...     0     0     0     0   \n",
       "3    0  0    0  0    0    0    0    0    0    0  ...     0     0     0     0   \n",
       "4    8  0    0  0    0    0    0    0    0    0  ...     0     0     0     0   \n",
       "..  .. ..  ... ..  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   \n",
       "994  5  0    0  0    0    0    0    0    0    0  ...     0     0     0     0   \n",
       "995  5  0    0  0    0    0    0    0    0    0  ...     0     0     0     0   \n",
       "996  6  0    0  0    0    0    0    0    0    1  ...     0     0     0     0   \n",
       "997  1  0    0  0    0    0    0    0    0    0  ...     0     0     0     0   \n",
       "998  9  0    0  0    0    0    0    0    0    0  ...     0     0     0     0   \n",
       "\n",
       "     1.41  1.42  1.43  1.44  1.45  0.81  \n",
       "0       0     0     0     0     0     0  \n",
       "1       0     1     1     1     1     0  \n",
       "2       0     0     0     0     0     0  \n",
       "3       0     0     0     0     0     0  \n",
       "4       0     0     0     0     0     0  \n",
       "..    ...   ...   ...   ...   ...   ...  \n",
       "994     0     0     0     0     0     0  \n",
       "995     0     0     0     0     0     0  \n",
       "996     0     0     0     0     0     0  \n",
       "997     0     0     0     0     0     0  \n",
       "998     0     0     0     0     0     0  \n",
       "\n",
       "[999 rows x 129 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "batch_size = 1024\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/largeTrain_Q3.csv')\n",
    "df_test = pd.read_csv('dataset/largeValidation_Q3.csv')\n",
    "train_y = df_train.iloc[:, 0]\n",
    "train_X = df_train.iloc[:, 1:]\n",
    "test_y = df_test.iloc[:, 0]\n",
    "test_X = df_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transforms=None):\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "         \n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X.iloc[i, :]\n",
    "        data = np.asarray(data)\n",
    "        \n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "            \n",
    "        if self.y is not None:\n",
    "            return (data, self.y[i])\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(train_X, train_y)\n",
    "test_data = MyDataset(test_X, test_y)\n",
    "\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=1024, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "#         self.softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "#         print(out.shape)\n",
    "#         out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNet(input_size, 100, num_classes).to(device)\n",
    "# criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_iterator, test_iterator, optimizer, criterion, device, epochs = 100):\n",
    "    avg_epoch = 0\n",
    "    avg_test_epoch = 0\n",
    "    \n",
    "    for e in tqdm(range(epochs), desc = \"Progress : \", position = 0, leave = True) : \n",
    "        epoch_loss = 0    \n",
    "        model.train()\n",
    "        epoch_test_loss = 0\n",
    "        for (x, y) in train_iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred= model(x.float())\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            test_loss = 0\n",
    "            \n",
    "            for (u,v) in test_iterator:\n",
    "                y_test_pred = model(u.float())\n",
    "                test_loss += criterion(y_test_pred, v).item()\n",
    "            test_loss = test_loss/len(test_iterator)  \n",
    "            epoch_test_loss += test_loss\n",
    "#         print(epoch_test_loss/len(train_iterator) ,epoch_loss / len(train_iterator) )        \n",
    "        avg_test_epoch += epoch_test_loss/len(train_iterator)        \n",
    "        avg_epoch +=(epoch_loss / len(train_iterator))\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    return avg_epoch/epochs, avg_test_epoch/epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = train(model,trainloader,testloader, optimizer , criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for n =  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|█████████████████████████████████████████████████████████████████████| 100/100 [12:44<00:00,  7.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss :  0.6642457783553336\n",
      "Average Validation Loss :  0.7875496702061758\n",
      "Model for n =  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|█████████████████████████████████████████████████████████████████████| 100/100 [14:35<00:00,  8.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss :  0.29244775255521127\n",
      "Average Validation Loss :  0.5615422285927667\n",
      "Model for n =  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|█████████████████████████████████████████████████████████████████████| 100/100 [12:05<00:00,  7.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss :  0.17313576152341223\n",
      "Average Validation Loss :  0.591699907928705\n",
      "Model for n =  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|█████████████████████████████████████████████████████████████████████| 100/100 [14:01<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss :  0.11769026785881985\n",
      "Average Validation Loss :  0.522913781205813\n",
      "Model for n =  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|█████████████████████████████████████████████████████████████████████| 100/100 [12:47<00:00,  7.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss :  0.08948867799921167\n",
      "Average Validation Loss :  0.5225038929449187\n"
     ]
    }
   ],
   "source": [
    "units = [5,20,50,100,200]\n",
    "losses = []\n",
    "for n in units :\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = NeuralNet(input_size, n, num_classes).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    print(\"Model for n = \", n)\n",
    "    train_loss, test_loss = train(model,trainloader,testloader, optimizer , criterion, device)\n",
    "    losses.append([train_loss, test_loss])\n",
    "    print(\"Average Training Loss : \", train_loss)\n",
    "    print(\"Average Validation Loss : \", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6642457783553336, 0.7875496702061758],\n",
       " [0.29244775255521127, 0.5615422285927667],\n",
       " [0.17313576152341223, 0.591699907928705],\n",
       " [0.11769026785881985, 0.522913781205813],\n",
       " [0.08948867799921167, 0.5225038929449187]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = np.array(losses)\n",
    "plt.plot(units,losses[], label = \"Average Training  Loss \" )\n",
    "plt.plot(units, clf_GS.validation_accuracy_history, label = \"Average Validation  Loss\")\n",
    "plt.xlabel('hidden units')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_iterator, test_iterator, optimizer, criterion, device, epochs = 100):\n",
    "    avg_epoch = []\n",
    "    avg_test_epoch = []\n",
    "    \n",
    "    for e in tqdm(range(epochs), desc = \"Progress : \", position = 0, leave = True) : \n",
    "        epoch_loss = 0    \n",
    "        model.train()\n",
    "        epoch_test_loss = 0\n",
    "        for (x, y) in train_iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred= model(x.float())\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            test_loss = 0\n",
    "            \n",
    "            for (u,v) in test_iterator:\n",
    "                y_test_pred = model(u.float())\n",
    "                test_loss += criterion(y_test_pred, v).item()\n",
    "            test_loss = test_loss/len(test_iterator)  \n",
    "            epoch_test_loss += test_loss\n",
    "#         print(epoch_test_loss/len(train_iterator) ,epoch_loss / len(train_iterator) )        \n",
    "        avg_test_epoch.append(epoch_test_loss/len(train_iterator))      \n",
    "        avg_epoch.append(epoch_loss / len(train_iterator))\n",
    "        \n",
    "    return avg_epoch, avg_test_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for l =  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|█████████████████████████████████████████████████████████████████████| 100/100 [10:26<00:00,  6.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss :  0.7658797559473253\n",
      "Average Validation Loss :  0.873876634173923\n",
      "Model for l =  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|█████████████████████████████████████████████████████████████████████| 100/100 [10:20<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss :  0.7438545272747673\n",
      "Average Validation Loss :  0.8700967090990807\n",
      "Model for l =  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress : 100%|█████████████████████████████████████████████████████████████████████| 100/100 [09:51<00:00,  5.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss :  1.2285192669100238\n",
      "Average Validation Loss :  1.2975009656283591\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.1,0.01,0.001]\n",
    "history = {}\n",
    "for l in lrs :\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = NeuralNet(input_size, 4, num_classes).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr = l)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    print(\"Model for l = \", l)\n",
    "    train_loss, test_loss = train(model,trainloader,testloader, optimizer , criterion, device)\n",
    "    history[l] = (train_loss, test_loss)\n",
    "    print(\"Average Training Loss : \", sum(train_loss)/len(train_loss))\n",
    "    print(\"Average Validation Loss : \", sum(test_loss)/len(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
